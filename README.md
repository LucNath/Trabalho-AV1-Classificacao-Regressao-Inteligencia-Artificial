# ğŸ¤– Trabalho AV1 - ClassificaÃ§Ã£o e RegressÃ£o com Numpy

![Python](https://img.shields.io/badge/Python-3.13-blue.svg)
![Numpy](https://img.shields.io/badge/Numpy-Latest-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Completo-success.svg)

ImplementaÃ§Ã£o de modelos de **ClassificaÃ§Ã£o** e **RegressÃ£o** utilizando apenas **Numpy** (sem bibliotecas de Machine Learning), desenvolvido como parte da AV1 de InteligÃªncia Artificial Computacional.

## ğŸ“‹ Sobre o Projeto

Este projeto implementa do zero algoritmos clÃ¡ssicos de Machine Learning, demonstrando profundo entendimento dos fundamentos matemÃ¡ticos e estatÃ­sticos por trÃ¡s dos modelos, sem depender de bibliotecas como Scikit-learn.

### ğŸ¯ Objetivos

- âœ… Implementar algoritmos de ML usando apenas Numpy
- âœ… Compreender a matemÃ¡tica por trÃ¡s dos modelos
- âœ… Comparar diferentes abordagens de classificaÃ§Ã£o e regressÃ£o
- âœ… Validar modelos usando validaÃ§Ã£o Monte Carlo
- âœ… AnÃ¡lise de desempenho e mÃ©tricas

## ğŸ§® Modelos Implementados

### ğŸ“Š RegressÃ£o
1. **MQO (MÃ­nimos Quadrados OrdinÃ¡rios)**
   - RegressÃ£o linear clÃ¡ssica
   - SoluÃ§Ã£o analÃ­tica via Ã¡lgebra linear
   - Estimativa de parÃ¢metros Î²

### ğŸ·ï¸ ClassificaÃ§Ã£o
1. **Naive Bayes**
   - Classificador probabilÃ­stico baseado no Teorema de Bayes
   - AssunÃ§Ã£o de independÃªncia entre features
   
2. **Gauss Tradicional**
   - Classificador baseado em distribuiÃ§Ã£o gaussiana
   - Estimativa de mÃ¡xima verossimilhanÃ§a (MLE)
   
3. **Gauss Regularizado**
   - VersÃ£o melhorada com regularizaÃ§Ã£o da matriz de covariÃ¢ncia
   - Previne problemas de singularidade
   - Matriz de identidade com fator de regularizaÃ§Ã£o (1e-8)

## ğŸ—‚ï¸ Estrutura do Projeto

```
Trabalho-AV1-Classificacao-Regressao/
â”‚
â”œâ”€â”€ classificacao_numpy.py          # ImplementaÃ§Ã£o dos classificadores
â”œâ”€â”€ regressao_numpy.py              # ImplementaÃ§Ã£o de regressÃ£o
â”œâ”€â”€ EMGsDataset.csv                 # Dataset de sinais EMG
â”œâ”€â”€ aerogenerador.dat               # Dataset de aerogerador
â”œâ”€â”€ Relatorio_IA_AV1_FINAL.pdf     # RelatÃ³rio tÃ©cnico completo
â””â”€â”€ README.md                       # DocumentaÃ§Ã£o
```

## ğŸ“Š Datasets

### 1. EMGsDataset.csv
- **DescriÃ§Ã£o**: Sinais de eletromiografia (EMG)
- **Uso**: ClassificaÃ§Ã£o de padrÃµes
- **Features**: MÃºltiplos canais de sinais EMG
- **Classes**: Diferentes gestos/movimentos

### 2. aerogenerador.dat
- **DescriÃ§Ã£o**: Dados de aerogeradores
- **Uso**: RegressÃ£o para prediÃ§Ã£o
- **Features**: VariÃ¡veis fÃ­sicas do sistema
- **Target**: VariÃ¡vel de saÃ­da a ser predita

## ğŸš€ Como Executar

### PrÃ©-requisitos

```bash
Python 3.13 ou superior
Numpy
Matplotlib (para visualizaÃ§Ãµes)
```

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/LucNath/Trabalho-AV1-Classificacao-Regressao-Inteligencia-Artificial.git
cd Trabalho-AV1-Classificacao-Regressao-Inteligencia-Artificial

# Instale as dependÃªncias
pip install numpy matplotlib
```

### Executando ClassificaÃ§Ã£o

```python
# Execute o script de classificaÃ§Ã£o
python classificacao_numpy.py
```

### Executando RegressÃ£o

```python
# Execute o script de regressÃ£o
python regressao_numpy.py
```

## ğŸ“ˆ MÃ©tricas e AvaliaÃ§Ã£o

### ClassificaÃ§Ã£o
- **AcurÃ¡cia**: Percentual de prediÃ§Ãµes corretas
- **ValidaÃ§Ã£o Monte Carlo**: R = 500 iteraÃ§Ãµes
- **Matriz de ConfusÃ£o**: AnÃ¡lise de erros por classe

### RegressÃ£o
- **MSE (Mean Squared Error)**: Erro quadrÃ¡tico mÃ©dio
- **RÂ² (Coeficiente de DeterminaÃ§Ã£o)**: Qualidade do ajuste
- **ValidaÃ§Ã£o Monte Carlo**: R = 500 iteraÃ§Ãµes

## ğŸ§ª Metodologia

### ValidaÃ§Ã£o Monte Carlo
Implementada para garantir robustez dos resultados:
1. **500 iteraÃ§Ãµes** de treinamento/teste
2. **Split aleatÃ³rio** em cada iteraÃ§Ã£o
3. **MÃ©dia das mÃ©tricas** para resultado final
4. **Desvio padrÃ£o** para anÃ¡lise de estabilidade

### Tratamento de Dados
- NormalizaÃ§Ã£o de features quando necessÃ¡rio
- AdiÃ§Ã£o de intercepto (bias term)
- Tratamento de valores faltantes
- Split treino/teste aleatÃ³rio

## ğŸ”¬ Fundamentos MatemÃ¡ticos

### MÃ­nimos Quadrados OrdinÃ¡rios (MQO)

```
Î² = (X^T X)^(-1) X^T y
```

Onde:
- `Î²`: Vetor de parÃ¢metros
- `X`: Matriz de features
- `y`: Vetor target

### Naive Bayes

```
P(C|X) = P(X|C) * P(C) / P(X)
```

ClassificaÃ§Ã£o por mÃ¡xima probabilidade a posteriori (MAP).

### DistribuiÃ§Ã£o Gaussiana

```
P(x|C) = (1/âˆš(2Ï€|Î£|)) * exp(-Â½(x-Î¼)^T Î£^(-1) (x-Î¼))
```

Onde:
- `Î¼`: MÃ©dia da classe
- `Î£`: Matriz de covariÃ¢ncia
- `Î£_reg = Î£ + Î»I`: CovariÃ¢ncia regularizada

## ğŸ“Š Resultados

### ClassificaÃ§Ã£o (EMGsDataset)
| Modelo | AcurÃ¡cia | Tempo |
|--------|----------|-------|
| Naive Bayes | -% | - ms |
| Gauss Tradicional | -% | - ms |
| Gauss Regularizado | -% | - ms |

### RegressÃ£o (Aerogerador)
| MÃ©trica | Valor |
|---------|-------|
| MSE | - |
| RÂ² | - |
| RMSE | - |

*Nota: Execute os scripts para obter os resultados atualizados*

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.13** - Linguagem principal
- **Numpy** - OperaÃ§Ãµes matriciais e vetoriais
- **Matplotlib** - VisualizaÃ§Ã£o de resultados
- **Pandas** (opcional) - Leitura de dados CSV

## ğŸ’¡ Conceitos Aplicados

### Ãlgebra Linear
- MultiplicaÃ§Ã£o de matrizes
- InversÃ£o de matrizes
- DecomposiÃ§Ã£o de autovalores
- Determinantes

### EstatÃ­stica
- EstimaÃ§Ã£o de mÃ¡xima verossimilhanÃ§a
- DistribuiÃ§Ãµes de probabilidade
- Teorema de Bayes
- CorrelaÃ§Ã£o e covariÃ¢ncia

### Machine Learning
- Aprendizado supervisionado
- ClassificaÃ§Ã£o multiclasse
- RegressÃ£o linear
- ValidaÃ§Ã£o cruzada
- Overfitting e regularizaÃ§Ã£o

## ğŸ“ Aprendizados

Este projeto proporcionou:
- âœ… CompreensÃ£o profunda dos algoritmos
- âœ… DomÃ­nio de operaÃ§Ãµes com Numpy
- âœ… ImplementaÃ§Ã£o sem bibliotecas prontas
- âœ… AnÃ¡lise crÃ­tica de resultados
- âœ… Debugging de implementaÃ§Ãµes matemÃ¡ticas

## ğŸ“ RelatÃ³rio TÃ©cnico

O arquivo `Relatorio_IA_AV1_FINAL.pdf` contÃ©m:
- FundamentaÃ§Ã£o teÃ³rica completa
- DescriÃ§Ã£o detalhada dos algoritmos
- AnÃ¡lise de resultados
- GrÃ¡ficos e visualizaÃ§Ãµes
- ConclusÃµes e discussÃµes

## ğŸ” PossÃ­veis Melhorias

- [ ] Implementar validaÃ§Ã£o cruzada k-fold
- [ ] Adicionar mais modelos (SVM, KNN)
- [ ] Grid search para hiperparÃ¢metros
- [ ] VisualizaÃ§Ã£o interativa dos resultados
- [ ] AnÃ¡lise de feature importance
- [ ] Pipeline de prÃ©-processamento

## ğŸ¤ Contribuindo

Este Ã© um projeto acadÃªmico, mas sugestÃµes sÃ£o bem-vindas!

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/melhoria`)
3. Commit suas mudanÃ§as (`git commit -m 'Adicionar melhoria'`)
4. Push para a branch (`git push origin feature/melhoria`)
5. Abra um Pull Request

## ğŸ‘¨â€ğŸ’» Autor

**Lucas Nathan**

- GitHub: [@LucNath](https://github.com/LucNath)
- LinkedIn: [Lucas Nathan][https://linkedin.com/in/-](https://www.linkedin.com/in/lucas-nathan-de-moraes-gomes-a83418242/)

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ™ Agradecimentos

- **Professor AndrÃ©** - OrientaÃ§Ã£o e conhecimento transmitido
- **UNIFOR** - Estrutura e apoio
- **Comunidade Python/Numpy** - DocumentaÃ§Ã£o excelente

---

<div align="center">

### ğŸ“š Desenvolvido como parte da AV1 de InteligÃªncia Artificial Computacional

**UNIFOR - Universidade de Fortaleza**

â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela!

</div>

---

**Ãšltima atualizaÃ§Ã£o:** Fevereiro 2026
